{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "32sGJNIZqTkQ"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import os\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "\n",
        "from skimage.filters import gaussian\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vj_8JrLQ6Sro",
        "outputId": "61a9602b-ba2c-4c02-f10e-61003147737f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = \"/content/drive/My Drive/ML_Reserch-Paper/data\"\n",
        "test_Data =\"/content/drive/My Drive/ML_Reserch-Paper/TestData\"\n",
        "normal_path = os.path.join(data_path, \"normal_skin\")\n",
        "lumpy_path = os.path.join(data_path, \"lumpy_skin\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utoOEEAu3x7v"
      },
      "outputs": [],
      "source": [
        "# Define target labels\n",
        "normal_label = 0\n",
        "lumpy_label = 1\n",
        "\n",
        "# Define image size\n",
        "img_width, img_height = 224, 224\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wBHBNnvJay3J"
      },
      "outputs": [],
      "source": [
        "def load_preprocess_image(img_path, label):\n",
        "    # Load image in grayscale mode\n",
        "    img = load_img(img_path, color_mode=\"grayscale\", target_size=(img_width, img_height))\n",
        "\n",
        "    # Convert image to array\n",
        "    img_array = img_to_array(img)\n",
        "\n",
        "    # Apply Gaussian blurring\n",
        "    blurred_img = gaussian(img_array, sigma=1, multichannel=False)\n",
        "\n",
        "    # Normalize pixel values to range (0, 1)\n",
        "    blurred_img /= 255.0\n",
        "\n",
        "    return blurred_img, label\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CRb2aN8I4lUn",
        "outputId": "825f8ae2-fb6b-4c96-d004-99f1b8223d59"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-4-6ceeb60b9de2>:9: FutureWarning: `multichannel` is a deprecated argument name for `gaussian`. It will be removed in version 1.0. Please use `channel_axis` instead.\n",
            "  blurred_img = gaussian(img_array, sigma=1, multichannel=False)\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "\n",
        "images = []\n",
        "labels = []\n",
        "\n",
        "for folder in [normal_path, lumpy_path]:\n",
        "    for filename in os.listdir(folder):\n",
        "        img_path = os.path.join(folder, filename)\n",
        "        img_array, label = load_preprocess_image(img_path, normal_label if folder == normal_path else lumpy_label)\n",
        "        images.append(img_array)\n",
        "        labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5TBgoe_A_JFb"
      },
      "outputs": [],
      "source": [
        "# Convert lists to numpy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ztqeSX1APpnr"
      },
      "outputs": [],
      "source": [
        "# # Ensure the data is balanced\n",
        "# min_samples = min(np.sum(labels == normal_label), np.sum(labels == lumpy_label))\n",
        "# balanced_indices = []\n",
        "# for label in [normal_label, lumpy_label]:\n",
        "#     class_indices = np.where(labels == label)[0]\n",
        "#     balanced_indices.extend(np.random.choice(class_indices, size=min_samples, replace=False))\n",
        "\n",
        "# images = images[balanced_indices]\n",
        "# labels = labels[balanced_indices]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Nl6ShLx5U4E"
      },
      "outputs": [],
      "source": [
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X_train = np.array(X_train)\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "# Reshape X_train and X_test to the expected format\n",
        "X_train = X_train.reshape(-1, img_width, img_height, 1)  # Adjust the number of channels if needed (e.g., 1 for grayscale)\n",
        "X_test = X_test.reshape(-1, img_width, img_height, 1)\n",
        "\n",
        "# Optional: Data augmentation using ImageDataGenerator\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    shear_range=0.2,\n",
        "    zoom_range=0.2,\n",
        "    horizontal_flip=True,\n",
        "    fill_mode=\"nearest\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kysUvBvkAegu",
        "outputId": "361e8e12-140e-41a3-f6d0-6586a82e3658"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8WwumZLe-Ger",
        "outputId": "0e3ed2ca-b552-4aec-f9c3-0651b13169e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "X_train=  259\n",
            "y_train=  259\n",
            "X_test=   65\n",
            "y_test =  65\n"
          ]
        }
      ],
      "source": [
        "print(\"X_train= \",len(X_train))\n",
        "print(\"y_train= \",len(y_train))\n",
        "\n",
        "print(\"X_test=  \",len(X_test))\n",
        "print(\"y_test = \",len(y_test))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YH7IXsGO7OZc"
      },
      "outputs": [],
      "source": [
        "# Create training and validation generators (for data augmentation)\n",
        "train_generator = datagen.flow(X_train, y_train, batch_size=12)\n",
        "validation_generator = datagen.flow(X_test, y_test, batch_size=12)\n",
        "\n",
        "# Use these generators for training your machine learning model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYkmJH4OvxQ3"
      },
      "outputs": [],
      "source": [
        "Model using VGG19\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Flatten, Dense\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Load the VGG19 model\n",
        "model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TP0aDMmFwAfZ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Add new layers to the model\n",
        "x = model.output\n",
        "x = Flatten()(x)\n",
        "x = Dense(256, activation='relu')(x)\n",
        "predictions = Dense(1, activation='sigmoid')(x)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W2U7X_4QwCDH"
      },
      "outputs": [],
      "source": [
        "# Create a new model with the added layers\n",
        "model = Model(inputs=model.input, outputs=predictions)\n",
        "\n",
        "# Freeze the weights of the pre-trained layers\n",
        "for layer in model.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer=Adam(learning_rate=0.001),\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-5_cgCyLwHwg"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "model.fit(train_generator,\n",
        "          steps_per_epoch=len(X_train) // 32,\n",
        "          epochs=15,\n",
        "          validation_data=validation_generator,\n",
        "          validation_steps=len(X_test) // 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fSMMlh73t73a"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model on the testing data\n",
        "loss, accuracy = model.evaluate(X_test, y_test)\n",
        "print(\"Overall accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eckx1IaOGUUp"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "\n",
        "# Modify the CNN architecture for grayscale images\n",
        "new_model = tf.keras.Sequential([\n",
        "    Conv2D(32, (3, 3), activation='relu', input_shape=(img_width, img_height, 1)),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(64, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(128, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Conv2D(256, (3, 3), activation='relu'),\n",
        "    MaxPooling2D(2, 2),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu'),\n",
        "    Dense(256, activation='relu'),  # Additional dense layer\n",
        "    Dense(128, activation='relu'),  # Additional dense layer\n",
        "    Dense(64, activation='relu'),   # Additional dense layer\n",
        "    Dense(1, activation='sigmoid')\n",
        "])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hEG6tHL4lule",
        "outputId": "7d856fab-664a-4435-a0b6-805d8c7dd57a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/25\n",
            "8/8 [==============================] - 27s 3s/step - loss: 0.8037 - accuracy: 0.6374 - val_loss: 0.6770 - val_accuracy: 0.5833\n",
            "Epoch 2/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.6665 - accuracy: 0.5495 - val_loss: 0.6661 - val_accuracy: 0.6667\n",
            "Epoch 3/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.6725 - accuracy: 0.6354 - val_loss: 0.6616 - val_accuracy: 0.6667\n",
            "Epoch 4/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.6754 - accuracy: 0.6042 - val_loss: 0.6753 - val_accuracy: 0.6250\n",
            "Epoch 5/25\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.6704 - accuracy: 0.5495 - val_loss: 0.6990 - val_accuracy: 0.5417\n",
            "Epoch 6/25\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.7036 - accuracy: 0.5604 - val_loss: 0.6786 - val_accuracy: 0.6250\n",
            "Epoch 7/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.6602 - accuracy: 0.5729 - val_loss: 0.7241 - val_accuracy: 0.5833\n",
            "Epoch 8/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.6335 - accuracy: 0.6484 - val_loss: 0.6562 - val_accuracy: 0.5833\n",
            "Epoch 9/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.6396 - accuracy: 0.6374 - val_loss: 0.7009 - val_accuracy: 0.7083\n",
            "Epoch 10/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.6460 - accuracy: 0.6354 - val_loss: 0.6288 - val_accuracy: 0.7500\n",
            "Epoch 11/25\n",
            "8/8 [==============================] - 15s 2s/step - loss: 0.6926 - accuracy: 0.6146 - val_loss: 0.6503 - val_accuracy: 0.6667\n",
            "Epoch 12/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.6291 - accuracy: 0.6703 - val_loss: 0.7273 - val_accuracy: 0.5833\n",
            "Epoch 13/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.7114 - accuracy: 0.5208 - val_loss: 0.6519 - val_accuracy: 0.5833\n",
            "Epoch 14/25\n",
            "8/8 [==============================] - 17s 2s/step - loss: 0.6671 - accuracy: 0.5938 - val_loss: 0.7035 - val_accuracy: 0.6250\n",
            "Epoch 15/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.6652 - accuracy: 0.6458 - val_loss: 0.6955 - val_accuracy: 0.4167\n",
            "Epoch 16/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.6312 - accuracy: 0.6667 - val_loss: 0.6244 - val_accuracy: 0.6667\n",
            "Epoch 17/25\n",
            "8/8 [==============================] - 15s 2s/step - loss: 0.6147 - accuracy: 0.6923 - val_loss: 0.5253 - val_accuracy: 0.7500\n",
            "Epoch 18/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.6970 - accuracy: 0.6042 - val_loss: 0.6073 - val_accuracy: 0.7500\n",
            "Epoch 19/25\n",
            "8/8 [==============================] - 15s 2s/step - loss: 0.6717 - accuracy: 0.6484 - val_loss: 0.6701 - val_accuracy: 0.5000\n",
            "Epoch 20/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.6751 - accuracy: 0.6042 - val_loss: 0.6502 - val_accuracy: 0.6250\n",
            "Epoch 21/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.6448 - accuracy: 0.6354 - val_loss: 0.7148 - val_accuracy: 0.5833\n",
            "Epoch 22/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.6238 - accuracy: 0.6875 - val_loss: 0.6666 - val_accuracy: 0.7083\n",
            "Epoch 23/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.6399 - accuracy: 0.6354 - val_loss: 0.5889 - val_accuracy: 0.7917\n",
            "Epoch 24/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.6417 - accuracy: 0.6264 - val_loss: 0.6092 - val_accuracy: 0.7083\n",
            "Epoch 25/25\n",
            "8/8 [==============================] - 16s 2s/step - loss: 0.6246 - accuracy: 0.6562 - val_loss: 0.6681 - val_accuracy: 0.5417\n"
          ]
        }
      ],
      "source": [
        "# Compile the model\n",
        "new_model.compile(optimizer='Adam',\n",
        "                  loss='binary_crossentropy',\n",
        "                  metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = new_model.fit(train_generator,\n",
        "                        steps_per_epoch=len(X_train) // 32,\n",
        "                        epochs=25,\n",
        "                        validation_data=validation_generator,\n",
        "                        validation_steps=len(X_test) // 32)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FfjCFpJzv_cC",
        "outputId": "23ff29f7-0683-4f08-e2a0-e0994769eecd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "6/6 [==============================] - 3s 553ms/step - loss: 0.6119 - accuracy: 0.6923\n",
            "Overall accuracy: 0.692307710647583\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the new_model on the testing data\n",
        "loss, accuracy = new_model.evaluate(validation_generator)\n",
        "print(\"Overall accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "weRmBzqgHEoC",
        "outputId": "349e512c-1ca6-4085-a9fd-e8a056c265a1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 1s 599ms/step\n",
            "Precision: 1.0\n",
            "Recall: 0.75\n",
            "F1-Score: 0.8571428571428571\n",
            "AUC-ROC: 0.875\n",
            "Confusion Matrix:\n",
            " [[8 0]\n",
            " [1 3]]\n",
            "Matthews Correlation Coefficient: 0.816496580927726\n",
            "Cohen's Kappa: 0.8\n"
          ]
        }
      ],
      "source": [
        "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, confusion_matrix, matthews_corrcoef, cohen_kappa_score\n",
        "# Get the test data and labels\n",
        "X_test, y_test = next(iter(validation_generator))\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = np.round(new_model.predict(X_test)).flatten()\n",
        "\n",
        "# Calculate the performance metrics\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "auc_roc = roc_auc_score(y_test, y_pred)\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "kappa = cohen_kappa_score(y_test, y_pred)\n",
        "\n",
        "print(\"Precision:\", precision)\n",
        "print(\"Recall:\", recall)\n",
        "print(\"F1-Score:\", f1)\n",
        "print(\"AUC-ROC:\", auc_roc)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Matthews Correlation Coefficient:\", mcc)\n",
        "print(\"Cohen's Kappa:\", kappa)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "R86fCXLsphu5"
      },
      "outputs": [],
      "source": [
        "# from google.colab import files\n",
        "\n",
        "# files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fqk_FFnHoC4O",
        "outputId": "c8335ded-197e-494c-ea7f-251b39588faf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 284ms/step\n",
            "The image is classified as lumpy skin.\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the single image\n",
        "img_path = \"augmented_image_2.jpg\"  # Replace with the path to your single image\n",
        "img = image.load_img(img_path, target_size=(img_width, img_height), color_mode=\"grayscale\")\n",
        "\n",
        "# Convert the image to a numpy array\n",
        "img_array = image.img_to_array(img)\n",
        "\n",
        "# Expand the dimensions of the image array to match the input shape expected by the model\n",
        "# (assuming your model expects input shape of (224, 224, 1))\n",
        "img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "# Normalize the pixel values (if needed)\n",
        "# img_array = img_array / 255.0  # Assuming pixel values are in the range [0, 255]\n",
        "\n",
        "# Make predictions using the model\n",
        "predictions = new_model.predict(img_array)\n",
        "\n",
        "# Interpret the predictions\n",
        "if predictions[0] > 0.5:\n",
        "    print(\"The image is classified as lumpy skin.\")\n",
        "else:\n",
        "    print(\"The image is classified as normal skin.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMit95kHgxKI"
      },
      "outputs": [],
      "source": [
        "\n",
        "# import numpy as np\n",
        "# from tensorflow.keras.preprocessing.image import array_to_img\n",
        "\n",
        "# # Define a directory to store the augmented images\n",
        "# augmented_data_dir = \"/content/drive/My Drive/ML_Reserch-Paper/AugmentedData\"\n",
        "# os.makedirs(augmented_data_dir, exist_ok=True)\n",
        "\n",
        "# # Define a function to save augmented images\n",
        "# def save_augmented_images(generator, num_images):\n",
        "#     # Reset the generator to start at the beginning\n",
        "#     generator.reset()\n",
        "\n",
        "#     # Loop through the generator to generate and save augmented images\n",
        "#     for i in range(num_images):\n",
        "#         # Generate a batch of augmented images\n",
        "#         batch_images, _ = next(generator)\n",
        "\n",
        "#         # Loop through the batch and save each augmented image\n",
        "#         for j in range(len(batch_images)):\n",
        "#             # Convert the augmented image from numpy array to PIL Image\n",
        "#             augmented_img = array_to_img(batch_images[j])\n",
        "\n",
        "#             # Save the augmented image to the specified directory\n",
        "#             img_path = os.path.join(augmented_data_dir, f\"augmented_image_{i * len(batch_images) + j}.jpg\")\n",
        "#             augmented_img.save(img_path)\n",
        "\n",
        "# # Save augmented images from the training generator\n",
        "# save_augmented_images(train_generator, num_images=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "VlnH4b4Fn_aw",
        "outputId": "7a9e9f61-133e-440e-9c52-60f362697f90"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'kwargs' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-3660a358e260>\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m new_model.save('my_model.h5', save_format='h5', include_optimizer=False,\n\u001b[1;32m     10\u001b[0m                 \u001b[0msignatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_traces\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m                 **kwargs)\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;31m# # new_model.save('my_model.h5', save_format='h5', include_optimizer=False,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'kwargs' is not defined"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from tensorflow.keras.models import save_model\n",
        "from tensorflow.keras.optimizers import Adamax\n",
        "# # Define the path to save the model\n",
        "model_save_path = os.path.join(\"/content/drive/My Drive\", \"ML_Reserch-Paper\", \"modelAdam.h5\")\n",
        "\n",
        "# # Save the model\n",
        "new_model.save(model_save_path)\n",
        "\n",
        "# # new_model.save('my_model.h5', save_format='h5', include_optimizer=False,\n",
        "# #                 signatures=None, options=None, save_traces=True,\n",
        "# #                 **kwargs)\n",
        "# model_save_path = os.path.join(\"/content/drive/My Drive\", \"ML_Reserch-Paper\", \"modelCNN.h5\")\n",
        "# new_model.save(model_save_path, custom_objects={'Adamax': Adamax})\n",
        "# new_model.save('my_model.h5', save_format='h5', include_optimizer=False,\n",
        "#                  signatures=None, options=None, save_traces=True,\n",
        "#                  **kwargs)\n",
        "# import pickle\n",
        "# import os\n",
        "\n",
        "# # Save the model to a .pkl file\n",
        "# model_save_path = os.path.join(\"/content/drive/My Drive\", \"ML_Reserch-Paper\", \"my_model.pkl\")\n",
        "# with open(model_save_path, 'wb') as file:\n",
        "#     pickle.dump(new_model, file)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ahUoxGSrHh7e"
      },
      "outputs": [],
      "source": [
        "from flask import Flask, request, jsonify\n",
        "import base64\n",
        "import io\n",
        "import tensorflow as tf\n",
        "\n",
        "app = Flask(__name__)\n",
        "new_model = ...  # Load your machine learning model here\n",
        "\n",
        "@app.route('/classify-image', methods=['POST'])\n",
        "def classify_image():\n",
        "    if 'image' not in request.files:\n",
        "        return jsonify({'error': 'No image provided'}), 400\n",
        "\n",
        "    img_file = request.files['image']\n",
        "    if img_file.filename == '':\n",
        "        return jsonify({'error': 'No image provided'}), 400\n",
        "\n",
        "    img = tf.io.decode_image(img_file.read(), channels=1)\n",
        "    img = tf.image.resize(img, [img_width, img_height])\n",
        "    img_array = np.expand_dims(img, axis=0)\n",
        "    predictions = new_model.predict(img_array)\n",
        "\n",
        "    if predictions[0] > 0.5:\n",
        "        result = \"The image is classified as lumpy skin.\"\n",
        "    else:\n",
        "        result = \"The image is classified as normal skin.\"\n",
        "\n",
        "    return jsonify({'result': result})\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    app.run(debug=True)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}